import os
import logging
import json
import datetime as dt
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from statsmodels.tsa.arima.model import ARIMA
from typing import Dict, List, Optional

logger = logging.getLogger("adaptive_thresholds")
logger.setLevel(logging.INFO)


class AdaptiveThresholds:
    def __init__(
        self,
        asset: str,
        storage_path: str = "thresholds_data",
        base_window: int = 14,          # –¥–æ–¥–∞–Ω–æ base_window
        volatility_multiplier: float = 1.5,
        regime_clusters: int = 3,         # –¥–æ–¥–∞–Ω–æ regime_clusters
        update_interval: int = 7,
        shock_sensitivity: float = 0.25
    ):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–¥–∞–ø—Ç–∏–≤–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤ –¥–ª—è –∞–∫—Ç–∏–≤—É.

        :param asset: –ù–∞–∑–≤–∞ –∞–∫—Ç–∏–≤—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, BTCUSDT).
        :param storage_path: –®–ª—è—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É –ø–æ—Ä–æ–≥—ñ–≤.
        :param update_interval: –ü–µ—Ä—ñ–æ–¥ (—É –¥–Ω—è—Ö) –¥–ª—è –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤.
        :param shock_sensitivity: –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç, –ø—ñ—Å–ª—è —è–∫–æ–≥–æ –∑–º—ñ–Ω–∏ –≤–≤–∞–∂–∞—é—Ç—å—Å—è –∞–Ω–æ–º–∞–ª—å–Ω–∏–º–∏.
        """
        self.asset = asset
        self.storage_path = storage_path
        self.base_window = base_window            # –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä
        self.volatility_multiplier = volatility_multiplier
        self.regime_clusters = regime_clusters      # –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä
        self.update_interval = update_interval
        self.shock_sensitivity = shock_sensitivity

        self.file_path = os.path.join(storage_path, f"{asset}_thresholds.json")
        self.ensure_storage_path()
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤
        self.thresholds = self.load_thresholds()
        self.current_regime = None

    def ensure_storage_path(self):
        """–°—Ç–≤–æ—Ä—é—î –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö, —è–∫—â–æ –≤–æ–Ω–∞ –Ω–µ —ñ—Å–Ω—É—î."""
        if not os.path.exists(self.storage_path):
            os.makedirs(self.storage_path)
            logger.info(f"üìÇ –°—Ç–≤–æ—Ä–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é {self.storage_path}")

    def load_thresholds(self) -> dict:
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø–æ—Ä–æ–≥–∏ –∑ —Ñ–∞–π–ª—É –∞–±–æ —Å—Ç–≤–æ—Ä—é—î –Ω–æ–≤—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º.

        :return: –°–ª–æ–≤–Ω–∏–∫ –∑ –ø–æ–ª—è–º–∏:
            {
                "global_thresholds": {},
                "short_term_thresholds": {},
                "last_update_day": 0,
                "history": []
            }
        """
        if os.path.exists(self.file_path):
            try:
                with open(self.file_path, "r") as f:
                    return json.load(f)
            except json.JSONDecodeError as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –¥–µ–∫–æ–¥—É–≤–∞–Ω–Ω—è JSON: {e}")
        logger.warning(f"‚ö†Ô∏è –ü–æ—Ä–æ–≥–∏ –¥–ª—è {self.asset} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Ä–æ–∂–Ω—ñ–π –Ω–∞–±—ñ—Ä.")
        return {
            "global_thresholds": {},
            "short_term_thresholds": {},
            "last_update_day": 0,
            "history": []
        }

    def save_thresholds(self):
        """–ó–±–µ—Ä—ñ–≥–∞—î –ø–æ—Ç–æ—á–Ω—ñ –ø–æ—Ä–æ–≥–∏ —É —Ñ–∞–π–ª —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON –∑ –≤—ñ–¥—Å—Ç—É–ø–∞–º–∏."""
        with open(self.file_path, "w") as f:
            json.dump(self.thresholds, f, indent=4)
        logger.info(f"üíæ –ü–æ—Ä–æ–≥–∏ –¥–ª—è {self.asset} –∑–±–µ—Ä–µ–∂–µ–Ω–æ -> {self.file_path}")

    def calculate_dynamic_thresholds(self, df: pd.DataFrame) -> Dict:
        """
        –†–æ–∑—Ä–∞—Ö–æ–≤—É—î –∞–¥–∞–ø—Ç–∏–≤–Ω—ñ –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–≤–∑–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞ —Ç–∞ –±–∞–∑–æ–≤–∏—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∏—Ö –º–µ—Ç–æ–¥—ñ–≤.
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –¥–∞–Ω—ñ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ–π –ø–µ—Ä—ñ–æ–¥ (base_window) –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö –∑–Ω–∞—á–µ–Ω—å,
        —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è, —Ç–æ—â–æ.

        :param df: DataFrame –∑ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ ('volatility', 'volume', 'price_change').
        :return: –°–ª–æ–≤–Ω–∏–∫ —ñ–∑ –ø–æ—Ä–æ–≥–∞–º–∏.
        """
        # –Ø–∫—â–æ —Å—Ç–æ–≤–ø–µ—Ü—å 'price_change' –≤—ñ–¥—Å—É—Ç–Ω—ñ–π, —Å—Ç–≤–æ—Ä—é—î–º–æ –π–æ–≥–æ
        if "price_change" not in df.columns:
            df["price_change"] = df["close"].pct_change()
            logger.debug("–°—Ç–æ–≤–ø–µ—Ü—å 'price_change' —Å—Ç–≤–æ—Ä–µ–Ω–æ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é pct_change().")
            
        window_size = min(self.update_interval, len(df))
        rolling_data = df.iloc[-window_size:]

        thresholds = {
            'volatility_median': float(rolling_data['volatility'].median()),
            'volatility_threshold': float(rolling_data['volatility'].median() * 1.2),
            'volume_threshold': float(rolling_data['volume'].quantile(0.8)),
            'avg_volume': float(rolling_data['volume'].mean()),
            'weekly_volume': float(rolling_data['volume'].rolling(7).mean().iloc[-1] if len(df) >= 7 else rolling_data['volume'].mean())
        }

        if 'rsi' in df.columns:
            rsi_vals = df['rsi'].dropna()
            if not rsi_vals.empty:
                thresholds.update({
                    'rsi_lower': float(rsi_vals.quantile(0.25)),
                    'rsi_upper': float(rsi_vals.quantile(0.75))
                })

        # –í–∏—è–≤–ª–µ–Ω–Ω—è —Ä–∏–Ω–∫–æ–≤–∏—Ö —Ä–µ–∂–∏–º—ñ–≤
        self.identify_market_regimes(df)
        # –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –ø–µ—Ä—ñ–æ–¥—É
        thresholds['forecast'] = self.predict_next_period(df)
        return thresholds

    def identify_market_regimes(self, df: pd.DataFrame):
        """
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î K-means –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó —Ä–∏–Ω–∫–æ–≤–∏—Ö —Ä–µ–∂–∏–º—ñ–≤ –∑–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏:
        –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å, –æ–±—Å—è–≥ —ñ –∑–º—ñ–Ω–∞ —Ü—ñ–Ω–∏.
        """
        features = df[['volatility', 'volume', 'price_change']].dropna()
        if len(features) >= 3:
            kmeans = KMeans(n_clusters=3)
            clusters = kmeans.fit_predict(features)
            self.current_regime = int(clusters[-1])
            self.thresholds['regimes'] = clusters.tolist()

    def predict_next_period(self, df: pd.DataFrame) -> Dict:
        """
        –ü—Ä–æ–≥–Ω–æ–∑—É—î –∑–Ω–∞—á–µ–Ω–Ω—è –∫–ª—é—á–æ–≤–∏—Ö –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤ –Ω–∞ –Ω–∞—Å—Ç—É–ø–Ω–∏–π –ø–µ—Ä—ñ–æ–¥ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é ARIMA.
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —ñ—Å—Ç–æ—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ –∑ self.thresholds['history'] –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞.

        :param df: DataFrame –∑ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ ('volatility', 'volume', 'price_change').
        :return: –°–ª–æ–≤–Ω–∏–∫ —ñ–∑ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤,
                 –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, {'volatility_median': 0.061, 'volume_threshold': 1300000.0, ...}
        """
        forecasts = {}
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏, –¥–ª—è —è–∫–∏—Ö –±—É–¥–µ–º–æ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞—Ç–∏ –Ω–∞—Å—Ç—É–ø–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è
        params = ['volatility_median', 'volume_threshold', 'avg_volume', 'weekly_volume']
        # –û—Ç—Ä–∏–º—É—î–º–æ —ñ—Å—Ç–æ—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ –∑ –∑–∞–ø–∏—Å—ñ–≤ —É self.thresholds['history']
        history = [entry["changes"] for entry in self.thresholds.get("history", [])]
        if not history:
            return self.thresholds.get("global_thresholds", {})

        for param in params:
            values = [entry[param] for entry in history if param in entry]
            if len(values) >= 5:
                try:
                    model = ARIMA(values, order=(1, 1, 1))
                    model_fit = model.fit()
                    forecast = float(model_fit.forecast(steps=1).iloc[0])
                    forecasts[param] = forecast
                except Exception as e:
                    logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –¥–ª—è {param}: {e}")
                    forecasts[param] = None
            else:
                forecasts[param] = None
        return forecasts

    def detect_anomalies(self, current: Dict, historical: List[Dict]) -> Dict:
        """
        –í–∏—è–≤–ª—è—î –∞–Ω–æ–º–∞–ª—ñ—ó —É –ø–æ—Ç–æ—á–Ω–∏—Ö –ø–æ—Ä–æ–≥–∞—Ö, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ Z-—Å–∫–æ—Ä–∏,
        –ø–æ—Ä—ñ–≤–Ω—é—é—á–∏ –∑ —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏.

        :param current: –ù–æ–≤—ñ –ø–æ—Ä–æ–≥–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è.
        :param historical: –°–ø–∏—Å–æ–∫ —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤ (—Å–ª–æ–≤–Ω–∏–∫—ñ–≤ –∑ –ø–æ—Ä–æ–≥–∞–º–∏).
        :return: –°–ª–æ–≤–Ω–∏–∫ –∑ –≤–∏—è–≤–ª–µ–Ω–∏–º–∏ –∞–Ω–æ–º–∞–ª—ñ—è–º–∏.
        """
        anomalies = {}
        for key in ['volatility', 'volume', 'price_change']:
            values = [entry[key] for entry in historical if key in entry]
            if len(values) > 10:
                mean_val = np.mean(values)
                std_val = np.std(values)
                if std_val > 0:
                    z_score = (current[key] - mean_val) / std_val
                    if abs(z_score) > self.shock_sensitivity:
                        anomalies[key] = {
                            'value': current[key],
                            'z_score': z_score,
                            'mean': mean_val,
                            'std': std_val
                        }
        return anomalies

    def adjust_for_anomalies(self, thresholds: Dict, anomalies: Dict) -> Dict:
        """
        –ü–ª–∞–≤–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è –ø–æ—Ä–æ–≥—ñ–≤ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –≤–∞–≥–æ–≤–∏—Ö –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤,
        —è–∫—â–æ –≤–∏—è–≤–ª–µ–Ω–æ –∞–Ω–æ–º–∞–ª—ñ—ó.
        """
        adjusted = thresholds.copy()
        for key in anomalies:
            # –ü–ª–∞–≤–Ω–µ –∑–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è –∑ –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–æ–º 0.2
            adjusted[key] = 0.8 * thresholds[key] + 0.2 * anomalies[key]['mean']
        return adjusted

    def update_prediction_model(self, new_data: pd.DataFrame):
        """
        –ú–æ–∂–ª–∏–≤–µ –ø–µ—Ä–µ—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö.
        """
        # –†–µ–∞–ª—ñ–∑—É–π—Ç–µ –ª–æ–≥—ñ–∫—É –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –ø—Ä–∏ –ø–æ—Ç—Ä–µ–±—ñ
        pass

    def update_thresholds(self, new_data: pd.DataFrame, current_day: int) -> Dict:
        """
        –û–Ω–æ–≤–ª—é—î –ø–æ—Ä–æ–≥–∏, –≤—Ä–∞—Ö–æ–≤—É—é—á–∏ –Ω–æ–≤—ñ –¥–∞–Ω—ñ —Ç–∞ —ñ—Å—Ç–æ—Ä–∏—á–Ω—É –¥–∏–Ω–∞–º—ñ–∫—É.
        
        :param new_data: DataFrame –∑ –Ω–æ–≤–∏–º–∏ –¥–∞–Ω–∏–º–∏.
        :param current_day: –ü–æ—Ç–æ—á–Ω–∏–π –¥–µ–Ω—å (—á–∏—Å–ª–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è).
        :return: –ù–æ–≤—ñ –ø–æ—Ä–æ–≥–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø—ñ—Å–ª—è –∫–æ—Ä–µ–∫—Ü—ñ—ó.
        """
        new_thresholds = self.calculate_dynamic_thresholds(new_data)
        history_entry = {
            "date": str(dt.date.today()),
            "changes": new_thresholds
        }

        # –û—Ç—Ä–∏–º—É—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é –∑–º—ñ–Ω
        historical = [entry["changes"] for entry in self.thresholds.get("history", [])]
        anomalies = self.detect_anomalies(new_thresholds, historical)
        if anomalies:
            logger.warning(f"–í–∏—è–≤–ª–µ–Ω–æ –∞–Ω–æ–º–∞–ª—ñ—ó: {list(anomalies.keys())}")
            new_thresholds = self.adjust_for_anomalies(new_thresholds, anomalies)

        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è –∫–æ—Ä–æ—Ç–∫–æ—Å—Ç—Ä–æ–∫–æ–≤–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤
        self.thresholds.setdefault("short_term_thresholds", {}).update(new_thresholds)
        last_update_day = self.thresholds.get("last_update_day", 0)
        if (current_day - last_update_day) >= self.update_interval:
            logger.info(f"üîÑ –û–Ω–æ–≤–ª–µ–Ω–Ω—è –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤ –¥–ª—è {self.asset}")
            self.thresholds["global_thresholds"] = self.thresholds["short_term_thresholds"].copy()
            self.thresholds["last_update_day"] = current_day

        self.thresholds.setdefault("history", []).append(history_entry)
        self.save_thresholds()
        return new_thresholds

    def analyze_historical_trends(self, days_back: int = 30) -> Dict[str, Dict[str, float]]:
        """
        –ê–Ω–∞–ª—ñ–∑—É—î —ñ—Å—Ç–æ—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ –∑–º—ñ–Ω –ø–æ—Ä–æ–≥—ñ–≤ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 'days_back' –¥–Ω—ñ–≤ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é
        –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó (np.polyfit) —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —Ç–µ–Ω–¥–µ–Ω—Ü—ñ—ó –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞.

        :param days_back: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–Ω—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.
        :return: –°–ª–æ–≤–Ω–∏–∫ –∑ —Ç–µ–Ω–¥–µ–Ω—Ü—ñ—è–º–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞,
                 –Ω–∞–ø—Ä–∏–∫–ª–∞–¥: {'volatility_threshold': {'slope': 0.001, 'intercept': 0.04}, ...}
        """
        history = self.thresholds.get("history", [])
        trends = {}
        filtered_history = [
            entry for entry in history
            if (dt.date.today() - dt.date.fromisoformat(entry["date"])).days <= days_back
        ]
        if not filtered_history:
            logger.info(f"–ó–∞ –æ—Å—Ç–∞–Ω–Ω—ñ {days_back} –¥–Ω—ñ–≤ —ñ—Å—Ç–æ—Ä—ñ—è –∑–º—ñ–Ω –ø–æ—Ä–æ–≥—ñ–≤ –≤—ñ–¥—Å—É—Ç–Ω—è.")
            return trends
        
        # –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞, —è–∫–∏–π –Ω–∞—Å —Ü—ñ–∫–∞–≤–∏—Ç—å
        parameters = ['volatility_median', 'volatility_threshold', 'volume_threshold', 'avg_volume', 'weekly_volume']
        for param in parameters:
            # –§–æ—Ä–º—É—î–º–æ —Å–ø–∏—Å–∫–∏ –¥–∞—Ç —ñ –∑–Ω–∞—á–µ–Ω—å
            dates = []
            values = []
            for entry in filtered_history:
                date_obj = dt.date.fromisoformat(entry["date"])
                if param in entry["changes"]:
                    dates.append(date_obj.toordinal())  # –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –¥–∞—Ç—É –≤ —á–∏—Å–ª–æ–≤–∏–π —Ñ–æ—Ä–º–∞—Ç
                    values.append(entry["changes"][param])
            if len(dates) >= 2:
                try:
                    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ np.polyfit –¥–ª—è –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó
                    slope, intercept = np.polyfit(dates, values, 1)
                    trends[param] = {"slope": slope, "intercept": intercept}
                except Exception as e:
                    logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É —Ç–µ–Ω–¥–µ–Ω—Ü—ñ–π –¥–ª—è {param}: {e}")
        return trends

    def get_adaptive_thresholds(self, df: pd.DataFrame, current_day: int) -> dict:
        """
        –ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –ø–æ—Ç—Ä—ñ–±–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –ø–æ—Ä–æ–≥—ñ–≤ (–∑–∞ —Ä–æ–∑–∫–ª–∞–¥–æ–º –∞–±–æ —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö),
        –≤–∏–∫–æ–Ω—É—î –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ update_thresholds —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î –∞–∫—Ç—É–∞–ª—å–Ω—ñ global_thresholds.
        
        :param df: DataFrame –∑ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏.
        :param current_day: –ü–æ—Ç–æ—á–Ω–∏–π –¥–µ–Ω—å.
        :return: –ê–∫—Ç—É–∞–ª—å–Ω—ñ –≥–ª–æ–±–∞–ª—å–Ω—ñ –ø–æ—Ä–æ–≥–∏.
        """
        saved_thresholds = self.thresholds.get("global_thresholds", {})
        last_update_day = self.thresholds.get("last_update_day", 0)
        need_recalculate = (current_day - last_update_day) >= self.update_interval or not saved_thresholds
        if need_recalculate:
            logger.info(f"[{self.asset}] –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –ø–æ—Ä–æ–≥—ñ–≤.")
            new_thresholds = {
                "volatility_median": float(df["volatility"].median()),
                "volatility_threshold": float(df["volatility"].median() * 1.2),
                "volume_threshold": float(df["volume"].quantile(0.8)),
                "avg_volume": float(df["volume"].mean()),
                "weekly_volume": float(df["volume"].rolling(7).mean().iloc[-1] if len(df) >= 7 else df["volume"].mean())
            }
            self.update_thresholds(new_data=df, current_day=current_day)
        else:
            logger.info(f"[{self.asset}] –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ—Ç–æ—á–Ω—ñ –ø–æ—Ä–æ–≥–∏ –±–µ–∑ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è.")
        return self.thresholds.get("global_thresholds", {})

    def generate_report(self, days_back: int = 7) -> str:
        """
        –ì–µ–Ω–µ—Ä—É—î –∑–≤—ñ—Ç –∑ —ñ—Å—Ç–æ—Ä—ñ—ó –∑–º—ñ–Ω –ø–æ—Ä–æ–≥—ñ–≤ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ days_back –¥–Ω—ñ–≤.
    
        :param days_back: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–Ω—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É —ñ—Å—Ç–æ—Ä—ñ—ó.
        :return: –¢–µ–∫—Å—Ç–æ–≤–∏–π –∑–≤—ñ—Ç.
        """
        # –õ–æ–∫–∞–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —á–∏—Å–µ–ª
        def format_number(num, decimals=2):
            try:
                return f"{num:,.{decimals}f}"
            except Exception:
                return str(num)
        
        relevant_history = [
            entry for entry in self.thresholds.get("history", [])
            if (dt.date.today() - dt.date.fromisoformat(entry["date"])).days <= days_back
        ]
        if not relevant_history:
            return f"–ó–∞ –æ—Å—Ç–∞–Ω–Ω—ñ {days_back} –¥–Ω—ñ–≤ –∑–º—ñ–Ω —É –ø–æ—Ä–æ–≥–∞—Ö –¥–ª—è {self.asset} –Ω–µ –∑–∞—Ñ—ñ–∫—Å–æ–≤–∞–Ω–æ."
    
        report_lines = [f"üìä –ó–≤—ñ—Ç –ø—Ä–æ –∞–¥–∞–ø—Ç–∏–≤–Ω—ñ –ø–æ—Ä–æ–≥–∏ –¥–ª—è {self.asset} (–æ—Å—Ç–∞–Ω–Ω—ñ {len(relevant_history)} –¥–Ω—ñ–≤):"]
        for entry in relevant_history:
            report_lines.append(f"\nüìÖ –î–∞—Ç–∞: {entry['date']}")
            for key, value in entry["changes"].items():
                report_lines.append(f"  üîπ {key}: {value}")
    
        trends = self.analyze_historical_trends(days_back)
        if trends:
            report_lines.append("\nüìà –¢–µ–Ω–¥–µ–Ω—Ü—ñ—ó –∑–º—ñ–Ω –ø–æ—Ä–æ–≥—ñ–≤:")
            for param, stats in trends.items():
                report_lines.append(
                    f"  {param}: –∑–º—ñ–Ω–∞ (slope) = {format_number(stats['slope'], 4)}, "
                    f"–±–∞–∑–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è (intercept) = {format_number(stats['intercept'], 4)}"
                )
    
        return "\n".join(report_lines)



# =============================================================================
# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
# =============================================================================
"""
    # 1) –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –∫–ª–∞—Å –ø–æ—Ä–æ–≥—ñ–≤
    adaptive_thresholds = AdaptiveThresholds(asset="BTCUSDT")

    # 2) –û—Ç—Ä–∏–º—É—î–º–æ (–∞–±–æ, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ, —Ä–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –π –æ–Ω–æ–≤–ª—é—î–º–æ) –≥–ª–æ–±–∞–ª—å–Ω—ñ –ø–æ—Ä–æ–≥–∏
    thresholds = adaptive_thresholds.get_adaptive_thresholds(df, current_day)
    logger.info(f"–¢–µ–ø–µ—Ä—ñ—à–Ω—ñ (–≥–ª–æ–±–∞–ª—å–Ω—ñ) –ø–æ—Ä–æ–≥–∏: {thresholds}")

    # 3) –§–æ—Ä–º—É—î–º–æ –∑–≤—ñ—Ç –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 30 –¥–Ω—ñ–≤
    report = adaptive_thresholds.generate_report(days_back=30)
    logger.info(f"\n{report}")
"""