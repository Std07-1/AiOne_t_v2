"""
–û—Å–Ω–æ–≤–Ω–∏–π –º–æ–¥—É–ª—å –∑–∞–ø—É—Å–∫—É —Å–∏—Å—Ç–µ–º–∏ AiOne_t
app/main.py
"""
import time
import json
import time
import asyncio
import logging
import os
import sys
from pathlib import Path
from dataclasses import asdict

import aiohttp
import pandas as pd
from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –Ü–º–ø–æ—Ä—Ç–∏ –±—ñ–∑–Ω–µ—Å-–ª–æ–≥—ñ–∫–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
from data.cache_handler import SimpleCacheHandler
from data.raw_data import OptimizedDataFetcher
from data.file_manager import FileManager
from stage1.asset_monitoring import AssetMonitorStage1, screening_producer
from data.ws_worker import WSWorker
from data.ram_buffer import RAMBuffer

from UI.ui_consumer import UI_Consumer
from stage1.optimized_asset_filter import get_prefiltered_symbols

from app.settings import settings
from rich.console import Console
from rich.logging import RichHandler

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑ .env
load_dotenv()

# --- –õ–æ–≥—É–≤–∞–Ω–Ω—è ---
main_logger = logging.getLogger("main")
main_logger.setLevel(logging.INFO)
main_logger.handlers.clear()
main_logger.addHandler(RichHandler(console=Console(stderr=True), show_path=False))
main_logger.propagate = False   # ‚Üê –ö—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–æ!

def debug_ram_buffer(buffer, symbols, tf="1m"):
    import time
    now = int(time.time() * 1000)
    for sym in symbols:
        bars = buffer.get(sym, tf, 3)
        if bars:
            last_ts = bars[-1]['timestamp']
            print(f"[{sym}] Last bar: {last_ts} | Age: {(now - last_ts) // 1000}s")
        else:
            print(f"[{sym}] No bars in RAMBuffer")

# –°—Ç–≤–æ—Ä—é—î–º–æ FastAPI-–¥–æ–¥–∞—Ç–æ–∫
app = FastAPI()

# –®–ª—è—Ö –¥–æ –∫–æ—Ä–µ–Ω—è –ø—Ä–æ–µ–∫—Ç—É
BASE_DIR = Path(__file__).resolve().parent.parent
# –ö–∞—Ç–∞–ª–æ–≥ –∑—ñ —Å—Ç–∞—Ç–∏—á–Ω–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏ (—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ WebApp)
STATIC_DIR = BASE_DIR / "static"

# 1) –†–æ–∑–¥–∞—á–∞ —Å—Ç–∞—Ç–∏—á–Ω–∏—Ö —Ä–µ—Å—É—Ä—Å—ñ–≤ –ø—ñ–¥ /static
app.mount(
    "/static",
    StaticFiles(directory=str(STATIC_DIR)),
    name="static",
)

# 2) GET / ‚Üí –ø–æ–≤–µ—Ä—Ç–∞—î index.html
@app.get("/", include_in_schema=False)
async def serve_index():
    """
    –í—ñ–¥–¥–∞—î –≥–æ–ª–æ–≤–Ω—É —Å—Ç–æ—Ä—ñ–Ω–∫—É WebApp (index.html).
    """
    index_path = STATIC_DIR / "index.html"
    return FileResponse(str(index_path))


# –ì–ª–æ–±–∞–ª—å–Ω–∏–π Redis-–∫–µ—à, —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î—Ç—å—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç—ñ
cache_handler: SimpleCacheHandler

@app.on_event("startup")
async def on_startup():
    """
    –ü–æ–¥—ñ—è –∑–∞–ø—É—Å–∫—É FastAPI:
      - –ü—ñ–¥–∫–ª—é—á–∞—î—Ç—å—Å—è –¥–æ Redis (—á–µ—Ä–µ–∑ URL –∞–±–æ host/port)
      - –ó–∞–ø—É—Å–∫–∞—î —Ñ–æ–Ω–æ–≤–∏–π —Ç–∞—Å–∫ –¥–ª—è pipeline
    """
    global cache_handler

    redis_url = os.getenv("REDIS_URL")
    if redis_url:
        cache_handler = SimpleCacheHandler.from_url(redis_url)
        main_logger.info("üîó –ü—ñ–¥–∫–ª—é—á–µ–Ω–æ –¥–æ Redis via URL: %s", redis_url)
    else:
        cache_handler = SimpleCacheHandler(
            host=settings.redis_host,
            port=settings.redis_port,
        )
        main_logger.info(
            "üîó –ü—ñ–¥–∫–ª—é—á–µ–Ω–æ –¥–æ Redis via host/port: %s:%s",
            settings.redis_host,
            settings.redis_port,
        )

    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –≥–æ–ª–æ–≤–Ω–∏–π –∫–æ–Ω–≤–µ—î—Ä –æ–±—Ä–æ–±–∫–∏ –≤ —Ñ–æ–Ω–æ–≤–æ–º—É —Ç–∞—Å–∫—É
    asyncio.create_task(run_pipeline())


@app.get("/api/data")
async def api_data():
    """
    –ï–Ω–¥–ø–æ—ñ–Ω—Ç –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥—É: –ø–æ–≤–µ—Ä—Ç–∞—î –æ—Å—Ç–∞–Ω–Ω—ñ –¥–∞–Ω—ñ asset_stats.
    –ß–∏—Ç–∞—î Redis-–∫–ª—é—á "asset_stats:global".
    """
    raw = await cache_handler.fetch_from_cache("asset_stats", "global")
    if not raw:
        # —è–∫—â–æ –¥–∞–Ω–∏—Ö —â–µ –Ω–µ–º–∞—î ‚Äî –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø—É—Å—Ç–∏–π —Å–ø–∏—Å–æ–∫
        return JSONResponse({"timestamp": int(time.time()), "assets": []})

    top10 = json.loads(raw.decode("utf-8"))
    return JSONResponse({"timestamp": int(time.time()), "assets": top10})


def validate_settings() -> None:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –∑–º—ñ–Ω–Ω—ñ –æ—Ç–æ—á–µ–Ω–Ω—è:
      - REDIS_URL –∞–±–æ (REDIS_HOST + REDIS_PORT)
      - BINANCE_API_KEY, BINANCE_SECRET_KEY
    """
    missing = []
    if not os.getenv("REDIS_URL"):
        if not settings.redis_host:
            missing.append("REDIS_HOST")
        if not settings.redis_port:
            missing.append("REDIS_PORT")

    if not settings.binance_api_key:
        missing.append("BINANCE_API_KEY")
    if not settings.binance_secret_key:
        missing.append("BINANCE_SECRET_KEY")

    if missing:
        raise ValueError(f"–í—ñ–¥—Å—É—Ç–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è: {', '.join(missing)}")
        
    main_logger.info("–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ ‚Äî OK.")


async def init_system() -> SimpleCacheHandler:
    """
    –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–æ–≤–Ω—ñ—à–Ω—ñ—Ö —Å–∏—Å—Ç–µ–º:
      - –í–∞–ª—ñ–¥–∞—Ü—ñ—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
      - –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ Redis
    –ü–æ–≤–µ—Ä—Ç–∞—î: —ñ–Ω—Å—Ç–∞–Ω—Å SimpleCacheHandler
    """
    validate_settings()

    redis_url = os.getenv("REDIS_URL")
    if redis_url:
        handler = SimpleCacheHandler.from_url(redis_url)
        #logger.debug("Redis —á–µ—Ä–µ–∑ URL: %s", redis_url)
    else:
        handler = SimpleCacheHandler(
            host=settings.redis_host,
            port=settings.redis_port,
        )
        #logger.debug(
        #    "Redis —á–µ—Ä–µ–∑ host/port: %s:%s",
        #    settings.redis_host,
        #    settings.redis_port,
        #)
    return handler


async def run_pipeline() -> None:
    """
    –û—Å–Ω–æ–≤–Ω–∏–π pipeline:
    1. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏ —Ç–∞ –∫–µ—à—É
    2. Pre-filter –∞–∫—Ç–∏–≤—ñ–≤
    3. –ó–∞–ø—É—Å–∫ ws_worker + RAMBuffer –¥–ª—è 1m –¥–∞–Ω–∏—Ö + healthcheck
    4. –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–Ω—ñ–Ω–≥—É (screening_producer) –¥–ª—è stage1
    5. (–û–ø—Ü—ñ–π–Ω–æ) –∑–∞–ø—É—Å–∫ UI/live-stats/fastapi
    """
    # 1. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
    cache = await init_system()
    file_manager = FileManager()
    buffer = RAMBuffer(max_bars=120)

    # 2. Pre-filter: –æ—Ç—Ä–∏–º—É—î–º–æ —Å–ø–∏—Å–æ–∫ –Ω–∞–π–ª—ñ–∫–≤—ñ–¥–Ω—ñ—à–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤ –¥–ª—è WS
    async with aiohttp.ClientSession() as session:
        fast_symbols = await get_prefiltered_symbols(
            session=session,
            cache_handler=cache,
            thresholds={
                "MIN_QUOTE_VOLUME": 1_000_000.0,
                "MIN_PRICE_CHANGE": 3.0,
                "MIN_OPEN_INTEREST": 500_000.0,
                "MAX_SYMBOLS": 350,   
            },
            dynamic=False,
        )
        if not fast_symbols:
            main_logger.warning("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∂–æ–¥–Ω–æ–≥–æ –∞–∫—Ç–∏–≤—É –ø—ñ—Å–ª—è pre-filter.")
            return
        main_logger.info("–ü—ñ—Å–ª—è pre-filter: %d —Å–∏–º–≤–æ–ª—ñ–≤", len(fast_symbols))
    
        # 2.1. –ó–∞–ø–∏—Å—É—î–º–æ —Ç—ñ–ª—å–∫–∏ —á–µ—Ä–µ–∑ set_fast_symbols/get_fast_symbols
        fast_symbols = [s.lower() for s in fast_symbols]

        await cache.set_fast_symbols(fast_symbols, ttl=600)
        actual_symbols = await cache.get_fast_symbols()
        main_logger.info("WS selector –∑–∞–ø–∏—Å–∞–Ω–æ —É Redis(%d symbols): %s", len(actual_symbols), list(actual_symbols)[:5])    #: %s", actual_symbols)
        if set(s.lower() for s in fast_symbols) != set(s.lower() for s in actual_symbols):
            main_logger.warning("‚ùóÔ∏è–†–æ–∑–±—ñ–∂–Ω—ñ—Å—Ç—å –º—ñ–∂ fast_symbols —ñ —Ç–∏–º, —â–æ –∑–∞–ø–∏—Å–∞–Ω–æ —É Redis!")

        # ‚îÄ‚îÄ‚îÄ Preload —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö 1m‚Äê–±–∞—Ä—ñ–≤ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Å—Ç–∞—Ä—Ç—É Stage1 ‚îÄ‚îÄ‚îÄ
        lookback = 50
        main_logger.debug(
            "–ü–æ—á–∏–Ω–∞—î–º–æ preload —ñ—Å—Ç–æ—Ä—ñ—ó: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ %d 1m-–±–∞—Ä—ñ–≤ –¥–ª—è %d —Å–∏–º–≤–æ–ª—ñ–≤‚Ä¶",
            lookback, len(fast_symbols)
        )
        # –°—Ç–≤–æ—Ä—é—î–º–æ fetcher –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        fetcher = OptimizedDataFetcher(cache_handler=cache, session=session)

        # ‚Ä¶ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π preload 1m ‚Ä¶
        hist_data = await fetcher.get_data_batch(
            fast_symbols,
            interval="1m",
            limit=lookback,
            min_candles=lookback,
            show_progress=True,
            read_cache=False,    # –≤–∏–º–∏–∫–∞—î–º–æ –∫–µ—à –ø—Ä–∏ preload
            write_cache=True     # –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ: –æ–¥—Ä–∞–∑—É –æ–Ω–æ–≤–∏–º–æ –∫–µ—à —Å–≤—ñ–∂–∏–º–∏ –¥–∞–Ω–∏–º–∏
        )

        # ‚îÄ‚îÄ‚îÄ Preload –¥–µ–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ ‚îÄ‚îÄ‚îÄ
        days = 30
        main_logger.debug("Preload Daily: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ %d –¥–µ–Ω–Ω–∏—Ö —Å–≤—ñ—á–æ–∫‚Ä¶", days)
        daily_data = await fetcher.get_data_batch(
            fast_symbols,
            interval="1d",
            limit=days,
            min_candles=days,
            show_progress=False,
            read_cache=False,
            write_cache=False
        )
        # –ü–µ—Ä–µ–¥–∞–º–æ –≤ –º–æ–Ω—ñ—Ç–æ—Ä –≥–ª–æ–±–∞–ª—å–Ω—ñ —Ä—ñ–≤–Ω—ñ

        # –ù–∞–ø–æ–≤–Ω—é—î–º–æ RAMBuffer –æ—Ç—Ä–∏–º–∞–Ω–∏–º–∏ —Å–≤—ñ—á–∫–∞–º–∏
        for sym, df in hist_data.items():
            for bar in df.to_dict("records"):
                # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ pandas.Timestamp ‚Üí ms
                ts = bar["timestamp"]
                if isinstance(ts, pd.Timestamp):
                    bar["timestamp"] = int(ts.value // 1_000_000)
                else:
                    bar["timestamp"] = int(ts)
                buffer.add(sym.lower(), "1m", bar)
        main_logger.debug(
            "Preload –∑–∞–≤–µ—Ä—à–µ–Ω–æ: —ñ—Å—Ç–æ—Ä—ñ—è –¥–æ–¥–∞–Ω–∞ –≤ RAMBuffer –¥–ª—è %d —Å–∏–º–≤–æ–ª—ñ–≤",
            len(hist_data)
        )

    # 3. –ó–∞–ø—É—Å–∫ WSWorker —Ç–∞ RAMBuffer
    ws_worker = WSWorker(
        symbols=fast_symbols,
        ram_buffer=buffer,
        redis_cache=cache,
    )

    # 3.1. HealthCheck ‚Äî –æ–∫—Ä–µ–º–∏–π —Ç–∞—Å–∫ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ, –∞–ª–µ strongly recommended!)
    async def ram_buffer_healthcheck(
        buffer,
        symbols,
        max_age=90,
        interval=30,
        ws_worker=None,
        tf="1m"
    ):
        """
        –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –∂–∏–≤—É—á–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö —É RAMBuffer.
        –Ø–∫—â–æ –¥–∞–Ω—ñ –ø–æ —Å–∏–º–≤–æ–ª—É –Ω–µ –æ–Ω–æ–≤–ª—é–≤–∞–ª–∏—Å—å >max_age —Å–µ–∫ ‚Äî –≤–≤–∞–∂–∞—î—Ç—å—Å—è "–º–µ—Ä—Ç–≤–∏–º".
        –ü—Ä–∏ –∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—ñ —Ç–∞–∫–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤ –ª–æ–≥—É—é—Ç—å—Å—è WARN, —ñ –æ–ø—Ü—ñ–π–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—î—Ç—å—Å—è WSWorker.
        """
        while True:
            now = int(time.time() * 1000)
            dead = []
            for sym in symbols:
                bars = buffer.get(sym, tf, 1)
                if not bars or (now - bars[-1]["timestamp"]) > max_age * 1000:
                    dead.append(sym)
            if dead:
                main_logger .debug("[HealthCheck] Symbols stalled: %s", dead)
                if ws_worker is not None:
                    main_logger .debug("[HealthCheck] Restarting WSWorker due to stalled symbols")
                    await ws_worker.stop()
                    asyncio.create_task(ws_worker.consume())
            else:
                main_logger .debug("[HealthCheck] All symbols are alive (checked %d symbols).", len(symbols))
            await asyncio.sleep(interval)

    ws_task = asyncio.create_task(ws_worker.consume())
    health_task = asyncio.create_task(ram_buffer_healthcheck(buffer, fast_symbols, ws_worker=ws_worker))

    # –ü—Ä–æ–≥—Ä—ñ–≤ RAMBuffer (–æ—á—ñ–∫—É—î–º–æ –ø–µ—Ä—à—ñ –±–∞—Ä–∏)
    await asyncio.sleep(5)
    #debug_ram_buffer(buffer, fast_symbols)

    # 4. AssetMonitor + screening_producer
    monitor = AssetMonitorStage1(cache_handler=cache)

    monitor.set_global_levels(daily_data)
    main_logger .debug("–ì–ª–æ–±–∞–ª—å–Ω—ñ —Ä—ñ–≤–Ω—ñ –¥–ª—è %d —Å–∏–º–≤–æ–ª—ñ–≤ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ", len(daily_data))

    queue = asyncio.Queue(maxsize=1)
    ui = UI_Consumer(vol_z_threshold=2.5)

    prod = asyncio.create_task(
        screening_producer(
            monitor,
            buffer,
            cache,            # –¥–æ–¥–∞—î–º–æ Redis‚Äë–∫–µ—à –¥–ª—è –¥–∏–Ω–∞–º—ñ–∫–∏
            fast_symbols,     # –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —Å–ø–∏—Å–æ–∫
            queue,
            timeframe="1m",
            lookback=50,
            interval_sec=30
        )
    )
    cons = asyncio.create_task(
        ui.ui_consumer(queue, refresh_rate=1.0, loading_delay=5.0, smooth_delay=0.1)
    )

    # –û—á—ñ–∫—É—î–º–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è —Ç–∞—Å–∫—ñ–≤ (Ctrl+C ‚Äî –∑–∞–≤–µ—Ä—à–∏—Ç—å –≤—Å–µ)
    await asyncio.gather(ws_task, health_task, prod, cons)

if __name__ == "__main__":
    try:
        asyncio.run(run_pipeline())
    except Exception as e:
        main_logger .error("–ü–æ–º–∏–ª–∫–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: %s", e, exc_info=True)
        sys.exit(1)
